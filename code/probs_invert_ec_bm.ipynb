{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e951127d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-11 15:34:21.890620: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-11 15:34:23.223180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10414 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1\n",
      "  0%|                                                                                                                                                                                      | 0/5 [00:00<?, ?it/s]2022-05-11 15:35:22.971520: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-05-11 15:35:25.771730: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function WeightNorm.call at 0x7fc01829e700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function WeightNorm.call at 0x7fc01829e700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function WeightNorm.call at 0x7fc01815d5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function WeightNorm.call at 0x7fc01815d5e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:52<00:00, 22.55s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:18<00:00,  3.61s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [01:13<00:00,  9.13s/it]\n",
      "4it [01:02, 15.53s/it]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tqdm\n",
    "from scipy.io import savemat\n",
    "from scipy.io import loadmat\n",
    "import cv2\n",
    "from numpy.linalg import norm as np_norm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../dependencies/')\n",
    "import dataset_utils\n",
    "import network_ec_bm as network\n",
    "import utils\n",
    "import zca\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "\n",
    "train_set = 'mnist'\n",
    "norm = None\n",
    "mode = 'grayscale'\n",
    "\n",
    "if mode == 'color':\n",
    "    input_shape = (32, 32, 3)\n",
    "    datasets = [\n",
    "        'svhn_cropped',\n",
    "        'cifar10',\n",
    "        'celeb_a',\n",
    "        'gtsrb',\n",
    "        'compcars',\n",
    "    ]\n",
    "    num_filters = 64\n",
    "    batch_size = 1024\n",
    "elif mode == 'grayscale':\n",
    "    input_shape = (32, 32, 1)\n",
    "    datasets = [\n",
    "        'mnist',\n",
    "        'fashion_mnist',\n",
    "        'emnist/letters',\n",
    "        'sign_lang'\n",
    "    ]\n",
    "    num_filters = 32\n",
    "    batch_size = 2048\n",
    "\n",
    "pre = 'ec_bm/'\n",
    "\n",
    "reg_weight = 0\n",
    "num_resnet = 2\n",
    "num_hierarchies = 4\n",
    "num_logistic_mix = 5\n",
    "num_filters = num_filters\n",
    "dropout_p = 0.3\n",
    "learning_rate = 1e-3\n",
    "use_weight_norm = True\n",
    "epochs = 100\n",
    "optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "if norm is None:\n",
    "    dir_str = 'original'\n",
    "elif norm == 'pctile-5':\n",
    "    dir_str = 'pctile-5'\n",
    "elif norm == 'channelwhiten':\n",
    "    dir_str = 'zca'\n",
    "elif norm == 'zca_original':\n",
    "    dir_str = 'zca_original'\n",
    "elif norm == 'histeq':\n",
    "    dir_str = 'histeq'\n",
    "    \n",
    "model_dir = '../saved_models/' + pre + dir_str + '/' + train_set + '/'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    \n",
    "if norm == 'zca_original':\n",
    "    zca_transform = zca.compute_zca(train_set)\n",
    "else:\n",
    "    zca_transform = None\n",
    "\n",
    "dist = network.PixelCNN(\n",
    "      image_shape=input_shape,\n",
    "      num_resnet=num_resnet,\n",
    "      num_hierarchies=num_hierarchies,\n",
    "      num_filters=num_filters,\n",
    "      num_logistic_mix=num_logistic_mix,\n",
    "      dropout_p=dropout_p,\n",
    "      use_weight_norm=use_weight_norm,\n",
    ")\n",
    "\n",
    "image_input = tfkl.Input(shape=input_shape)\n",
    "log_prob = dist.log_prob(image_input)\n",
    "model = tfk.Model(inputs=image_input, outputs=log_prob)\n",
    "model.add_loss(-tf.reduce_mean(log_prob))\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "model.build([None] + list(input_shape))\n",
    "model.load_weights(model_dir+'weights')\n",
    "    \n",
    "probs = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    \n",
    "    _, _, ds_test = dataset_utils.get_dataset(\n",
    "          dataset,\n",
    "          batch_size,\n",
    "          mode,\n",
    "          normalize=norm,\n",
    "          dequantize=False,\n",
    "          visible_dist='mixture_of_logistics',\n",
    "          zca_transform=zca_transform,\n",
    "          mutation_rate=0\n",
    "      )\n",
    "    \n",
    "    tmp = []\n",
    "    tmp_inv = []\n",
    "    for test_batch in tqdm.tqdm(ds_test):\n",
    "        batch = tf.cast(test_batch, tf.float32).numpy()\n",
    "        tmp.append(dist.log_prob(batch, training=False).numpy())\n",
    "        tmp_inv.append(dist.log_prob(255-batch, training=False).numpy())\n",
    "            \n",
    "    tmp = np.expand_dims(np.concatenate(tmp, axis=0),axis=-1)\n",
    "    tmp_inv = np.expand_dims(np.concatenate(tmp_inv, axis=0),axis=-1)\n",
    "    \n",
    "    probs[dataset+'_regular'] = tmp\n",
    "    probs[dataset+'_invert'] = tmp_inv\n",
    "    probs[dataset] = tmp - tmp_inv\n",
    "\n",
    "if train_set == 'emnist/letters':\n",
    "    train_set = 'emnist_letters'\n",
    "    \n",
    "dir_str1 = pre + dir_str + '_pixel_inverted'\n",
    "\n",
    "save_dir = '../probs/' + dir_str1 + '/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "savemat(save_dir + train_set + '.mat', probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

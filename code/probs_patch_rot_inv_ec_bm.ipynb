{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6afde814",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 23:37:57.753836: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-09 23:37:58.184531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10407 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:41:00.0, compute capability: 6.1\n",
      "  0%|                                                                                                                                                                                      | 0/5 [00:00<?, ?it/s]2022-05-09 23:38:10.633103: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-05-09 23:38:11.173515: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function WeightNorm.call at 0x7fcee0211790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function WeightNorm.call at 0x7fcee0211790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function WeightNorm.call at 0x7fcee006b040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function WeightNorm.call at 0x7fcee006b040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:44<00:00, 32.88s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [02:32<00:00, 30.42s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [03:58<00:00, 29.87s/it]\n",
      "4it [02:02, 30.64s/it]\n",
      "5it [02:31, 30.37s/it]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tqdm\n",
    "from scipy.io import savemat\n",
    "import cv2\n",
    "from scipy.special import factorial\n",
    "import itertools\n",
    "from numpy.linalg import norm as np_norm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../dependencies/')\n",
    "import dataset_utils\n",
    "import network_ec_bm as network\n",
    "import utils\n",
    "import zca\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "\n",
    "def rotate(img, angle):\n",
    "    rotated_img = np.zeros(img.shape)\n",
    "    if angle == 90:\n",
    "        rot_func = cv2.cv2.ROTATE_90_CLOCKWISE\n",
    "    elif angle == 180:\n",
    "        rot_func = cv2.cv2.ROTATE_180\n",
    "    elif angle == 270:\n",
    "        rot_func = cv2.ROTATE_90_COUNTERCLOCKWISE\n",
    "    for i in range (img.shape[0]):\n",
    "        temp = cv2.rotate(img[i,:,:,:], rot_func)\n",
    "        if len(temp.shape) == 2:\n",
    "            temp = np.expand_dims(temp, axis=-1)\n",
    "        rotated_img[i,:,:,:] = temp\n",
    "    return np.round(rotated_img)\n",
    "\n",
    "def rotate_inv(img, angle):\n",
    "    rotated_img = np.zeros(img.shape)\n",
    "    if angle == 90:\n",
    "        rot_func = cv2.cv2.ROTATE_90_CLOCKWISE\n",
    "    elif angle == 180:\n",
    "        rot_func = cv2.cv2.ROTATE_180\n",
    "    elif angle == 270:\n",
    "        rot_func = cv2.ROTATE_90_COUNTERCLOCKWISE\n",
    "    for i in range (img.shape[0]):\n",
    "        temp = cv2.rotate(cv2.flip(img[i,:,:,:],1), rot_func)\n",
    "        if len(temp.shape) == 2:\n",
    "            temp = np.expand_dims(temp, axis=-1)\n",
    "        rotated_img[i,:,:,:] = temp\n",
    "    return np.round(rotated_img)\n",
    "\n",
    "def inv(img):\n",
    "    inverted_img = np.zeros(img.shape)\n",
    "    for i in range (img.shape[0]):\n",
    "        temp = cv2.flip(img[i,:,:,:],1)\n",
    "        if len(temp.shape) == 2:\n",
    "            temp = np.expand_dims(temp, axis=-1)\n",
    "        inverted_img[i,:,:,:] = temp\n",
    "    return np.round(inverted_img)\n",
    "\n",
    "def derangement(n):\n",
    "    orders = np.array(list(itertools.permutations(np.arange(n*n))))\n",
    "    tmp = []\n",
    "    for i in range (orders.shape[0]):\n",
    "        count = 0\n",
    "        for j in range (orders.shape[1]):\n",
    "            if orders[i,j] == j:\n",
    "                count += 1\n",
    "        if count == 0:\n",
    "            tmp.append(orders[i,:])\n",
    "    return np.array(tmp), np.array(tmp).shape[0]\n",
    "\n",
    "def permutate(n):\n",
    "    x = np.array(list(itertools.permutations(range(0, n*n))))\n",
    "    x = np.delete(x, 0, 0)\n",
    "    for i in range (n*n):\n",
    "        x = np.concatenate(( np.concatenate((x, np.zeros((x.shape[0], 1))), axis=1),\n",
    "                             np.concatenate((x, np.ones((x.shape[0], 1))), axis=1)),\n",
    "                             axis=0)\n",
    "    for i in range (n*n):\n",
    "        x = np.concatenate(( np.concatenate((x, np.zeros((x.shape[0], 1))), axis=1),\n",
    "                             np.concatenate((x, np.ones((x.shape[0], 1))), axis=1),\n",
    "                             np.concatenate((x, 2*np.ones((x.shape[0], 1))), axis=1)),\n",
    "                             axis=0)\n",
    "    return x.astype('int32')\n",
    "\n",
    "def rotate_config(imgs, angle, inverse):\n",
    "    if inverse == 1:\n",
    "        imgs = inv(imgs)\n",
    "    if angle == 0:\n",
    "        imgs = rotate(imgs, 90)\n",
    "    elif angle == 1:\n",
    "        imgs = rotate(imgs, 180)\n",
    "    elif angle == 2:\n",
    "        imgs = rotate(imgs, 270)\n",
    "    return imgs\n",
    "        \n",
    "def patch_shuffle(imgs, n, orders, shuffles):\n",
    "    \n",
    "    shap = imgs.shape\n",
    "    patches = np.zeros((shap[0], int(shap[1]/n), int(shap[2]/n), shap[3], int(n*n)))\n",
    "    patch_shap = patches.shape\n",
    "    shuffled = np.zeros((shap[0], shap[1], shap[2], shap[3], orders.shape[0]))\n",
    "            \n",
    "    for k in range (orders.shape[0]):\n",
    "        temp = imgs.copy()\n",
    "        for i in range (n):\n",
    "            for j in range (n):\n",
    "                patches[:,:,:,:,i*n+j] = temp[:, i*(patch_shap[1]):(i+1)*(patch_shap[1]),\n",
    "                                              j*(patch_shap[2]):(j+1)*(patch_shap[2]), :]\n",
    "        for i in range (n*n):\n",
    "            patches[:,:,:,:,i] = rotate_config(patches[:,:,:,:,i], np.squeeze(orders[k,2*n*n+i]),\n",
    "                                               np.squeeze(orders[k,n*n+i]))\n",
    "        for i in range (n):\n",
    "            for j in range (n):\n",
    "                shuffled[:, i*(patch_shap[1]):(i+1)*(patch_shap[1]), j*(patch_shap[2]):(j+1)*(patch_shap[2])\n",
    "                         , :, k] = patches[:,:,:,:,np.squeeze(orders[k,i*n+j])]\n",
    "    return shuffled\n",
    "    \n",
    "def dissimilarity(a,b):\n",
    "    cos = np.zeros(a.shape[0])\n",
    "    for i in range (a.shape[0]):\n",
    "        cos[i] = (1 - (np.dot(a[i,:,:,:].flatten(), b[i,:,:,:].flatten())/(np_norm(a[i,:,:,:].flatten())*np_norm(b[i,:,:,:].flatten()))))/2\n",
    "    return cos\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfk = tf.keras\n",
    "tfkl = tf.keras.layers\n",
    "\n",
    "train_set = 'sign_lang'\n",
    "norm = None\n",
    "input_shape = (32,32,3)\n",
    "n_patches = 2\n",
    "orders = permutate(n_patches)\n",
    "shuffles = 20\n",
    "samples = np.random.randint(0, high=orders.shape[0], size=shuffles)\n",
    "orders = orders[samples,:]\n",
    "mode = 'grayscale'\n",
    "pre = 'ec_bm/'\n",
    "\n",
    "if mode == 'color':\n",
    "    input_shape = (32, 32, 3)\n",
    "    datasets = [\n",
    "        'svhn_cropped',\n",
    "        'cifar10',\n",
    "        'celeb_a',\n",
    "        'gtsrb',\n",
    "        'compcars',\n",
    "        'noise'\n",
    "    ]\n",
    "    num_filters = 64\n",
    "    batch_size = 512\n",
    "elif mode == 'grayscale':\n",
    "    input_shape = (32, 32, 1)\n",
    "    datasets = [\n",
    "        'mnist',\n",
    "        'fashion_mnist',\n",
    "        'emnist/letters',\n",
    "        'sign_lang',\n",
    "        'noise'\n",
    "    ]\n",
    "    num_filters = 32\n",
    "    batch_size = 2048\n",
    "\n",
    "reg_weight = 0\n",
    "num_resnet = 2\n",
    "num_hierarchies = 4\n",
    "num_logistic_mix = 5\n",
    "num_filters = num_filters\n",
    "dropout_p = 0.3\n",
    "learning_rate = 1e-3\n",
    "use_weight_norm = True\n",
    "epochs = 100\n",
    "optimizer = tf.optimizers.Adam(learning_rate=learning_rate)\n",
    "    \n",
    "if norm is None:\n",
    "    dir_str = 'original'\n",
    "elif norm == 'pctile-5':\n",
    "    dir_str = 'pctile-5'\n",
    "elif norm == 'channelwhiten':\n",
    "    dir_str = 'zca'\n",
    "elif norm == 'zca_original':\n",
    "    dir_str = 'zca_original'\n",
    "elif norm == 'histeq':\n",
    "    dir_str = 'histeq'\n",
    "    \n",
    "model_dir = '../saved_models/' + pre + dir_str + '/' + train_set + '/'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "    \n",
    "if norm == 'zca_original':\n",
    "    zca_transform = zca.compute_zca(train_set)\n",
    "else:\n",
    "    zca_transform = None\n",
    "\n",
    "dist = network.PixelCNN(\n",
    "      image_shape=input_shape,\n",
    "      num_resnet=num_resnet,\n",
    "      num_hierarchies=num_hierarchies,\n",
    "      num_filters=num_filters,\n",
    "      num_logistic_mix=num_logistic_mix,\n",
    "      dropout_p=dropout_p,\n",
    "      use_weight_norm=use_weight_norm,\n",
    ")\n",
    "\n",
    "image_input = tfkl.Input(shape=input_shape)\n",
    "log_prob = dist.log_prob(image_input)\n",
    "model = tfk.Model(inputs=image_input, outputs=log_prob)\n",
    "model.add_loss(-tf.reduce_mean(log_prob))\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "model.build([None] + list(input_shape))\n",
    "model.load_weights(model_dir+'weights')\n",
    "\n",
    "probs = {}\n",
    "\n",
    "for dataset in datasets:\n",
    "    \n",
    "    _, _, ds_test = dataset_utils.get_dataset(\n",
    "          dataset,\n",
    "          batch_size,\n",
    "          mode,\n",
    "          normalize=norm,\n",
    "          dequantize=False,\n",
    "          visible_dist='mixture_of_logistics',\n",
    "          zca_transform=zca_transform,\n",
    "          mutation_rate=0\n",
    "      )\n",
    "    \n",
    "    tmp = []\n",
    "    for i in range (shuffles):\n",
    "        globals()['tmp_'+str(i)] = []\n",
    "\n",
    "    for test_batch in tqdm.tqdm(ds_test):\n",
    "        batch = tf.cast(test_batch, tf.float32).numpy()\n",
    "        tmp.append(dist.log_prob(batch, training=False).numpy())\n",
    "        patches = patch_shuffle(batch, n_patches, orders, shuffles)\n",
    "        for i in range (shuffles):\n",
    "            globals()['tmp_'+str(i)].append(dist.log_prob(np.round(patches[:,:,:,:,i]), training=False).numpy())\n",
    "\n",
    "    tmp = np.expand_dims(np.concatenate(tmp, axis=0),axis=-1)\n",
    "\n",
    "    probs[dataset+'_regular'] = tmp\n",
    "    for i in range (shuffles):\n",
    "        globals()['tmp_'+str(i)] = np.expand_dims(np.concatenate(globals()['tmp_'+str(i)], axis=0),axis=-1)\n",
    "\n",
    "    for i in range (shuffles):\n",
    "        probs[dataset+'_shuffle_'+str(i)] = globals()['tmp_'+str(i)]\n",
    "        if i == 0:\n",
    "            probs[dataset] = tmp - globals()['tmp_'+str(i)]\n",
    "        else:\n",
    "            probs[dataset] += tmp - globals()['tmp_'+str(i)]\n",
    "\n",
    "\n",
    "if train_set == 'emnist/letters':\n",
    "    train_set = 'emnist_letters'\n",
    "    \n",
    "dir_str1 = pre + dir_str + '_patch_inv_rot_' + str(shuffles) + '_shuffles'\n",
    "\n",
    "save_dir = '../probs/' + dir_str1 + '/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "savemat(save_dir + train_set + '.mat', probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
